[[tests]]
name = "invalid-utf8-literal1"
regex = '\xFF'
input = '\xFF'
matches = [[0, 1]]
unicode = false
utf8 = false
unescape = true


[[tests]]
name = "mixed"
regex = '(?:.+)(?-u)(?:.+)'
input = '\xCE\x93\xCE\x94\xFF'
matches = [[0, 5]]
utf8 = false
unescape = true


[[tests]]
name = "case1"
regex = "a"
input = "A"
matches = [[0, 1]]
case_insensitive = true
unicode = false

[[tests]]
name = "case2"
regex = "[a-z]+"
input = "AaAaA"
matches = [[0, 5]]
case_insensitive = true
unicode = false

[[tests]]
name = "case3"
regex = "[a-z]+"
input = "aA\u212AaA"
matches = [[0, 7]]
case_insensitive = true

[[tests]]
name = "case4"
regex = "[a-z]+"
input = "aA\u212AaA"
matches = [[0, 2], [5, 7]]
case_insensitive = true
unicode = false


[[tests]]
name = "negate1"
regex = "[^a]"
input = "δ"
matches = [[0, 2]]

[[tests]]
name = "negate2"
regex = "[^a]"
input = "δ"
matches = [[0, 1], [1, 2]]
unicode = false
utf8 = false


[[tests]]
name = "dotstar-prefix1"
regex = "a"
input = '\xFFa'
matches = [[1, 2]]
unicode = false
utf8 = false
unescape = true

[[tests]]
name = "dotstar-prefix2"
regex = "a"
input = '\xFFa'
matches = [[1, 2]]
utf8 = false
unescape = true


[[tests]]
name = "null-bytes1"
regex = '[^\x00]+\x00'
input = 'foo\x00'
matches = [[0, 4]]
unicode = false
utf8 = false
unescape = true


[[tests]]
name = "word-ascii"
regex = '\w+'
input = "aδ"
matches = [[0, 1]]
unicode = false

[[tests]]
name = "word-unicode"
regex = '\w+'
input = "aδ"
matches = [[0, 3]]

[[tests]]
name = "decimal-ascii"
regex = '\d+'
input = "1२३9"
matches = [[0, 1], [7, 8]]
unicode = false

[[tests]]
name = "decimal-unicode"
regex = '\d+'
input = "1२३9"
matches = [[0, 8]]

[[tests]]
name = "space-ascii"
regex = '\s+'
input = " \u1680"
matches = [[0, 1]]
unicode = false

[[tests]]
name = "space-unicode"
regex = '\s+'
input = " \u1680"
matches = [[0, 4]]


[[tests]]
# See: https://github.com/rust-lang/regex/issues/484
name = "iter1-bytes"
regex = ''
input = "☃"
matches = [[0, 0], [1, 1], [2, 2], [3, 3]]
utf8 = false

[[tests]]
# See: https://github.com/rust-lang/regex/issues/484
name = "iter1-utf8"
regex = ''
input = "☃"
matches = [[0, 0], [3, 3]]

[[tests]]
# See: https://github.com/rust-lang/regex/issues/484
# Note that iter2-utf8 doesn't make sense here, since the input isn't UTF-8.
name = "iter2-bytes"
regex = ''
input = 'b\xFFr'
matches = [[0, 0], [1, 1], [2, 2], [3, 3]]
unescape = true
utf8 = false


# These test that unanchored prefixes can munch through invalid UTF-8 even when
# utf8 is enabled.
#
# This test actually reflects an interesting simplification in how the Thompson
# NFA is constructed. It used to be that the NFA could be built with an
# unanchored prefix that either matched any byte or _only_ matched valid UTF-8.
# But the latter turns out to be pretty precarious when it comes to prefilters,
# because if you search a haystack that contains invalid UTF-8 but have an
# unanchored prefix that requires UTF-8, then prefilters are no longer a valid
# optimization because you actually have to check that everything is valid
# UTF-8.
#
# Originally, I had thought that we needed a valid UTF-8 unanchored prefix in
# order to guarantee that we only match at valid UTF-8 boundaries. But this
# isn't actually true! There are really only two things to consider here:
#
# 1) Will a regex match split an encoded codepoint? No. Because by construction,
# we ensure that a MATCH state can only be reached by following valid UTF-8 (assuming
# all of the UTF-8 modes are enabled).
#
# 2) Will a regex match arbitrary bytes that aren't valid UTF-8? Again, no,
# assuming all of the UTF-8 modes are enabled.
[[tests]]
name = "unanchored-invalid-utf8-match-100"
regex = '[a-z]'
input = '\xFFa\xFF'
matches = [[1, 2]]
unescape = true
utf8 = false

[[tests]]
name = "unanchored-invalid-utf8-match-101"
regex = '[a-z]'
input = '\xFFa\xFF'
matches = [[1, 2]]
unescape = true
utf8 = true

# This test shows that we can still prevent a match from occurring by requiring
# that valid UTF-8 match by inserting our own unanchored prefix. Thus, if the
# behavior of not munching through invalid UTF-8 anywhere is needed, then it
# can be achieved thusly.
[[tests]]
name = "unanchored-invalid-utf8-nomatch"
regex = '^(?s:.)*?[a-z]'
input = '\xFFa\xFF'
matches = []
unescape = true
utf8 = true

# FIXME
#
# This test fails on every regex engine except for one-pass, and it reveals
# a fundamental API problem: whether a search is anchored or not should be
# a property of the 'Input' configuration. Some regex engines can *only*
# do anchored searches (like one-pass), and that's fine, but otherwise, every
# regex engine should always support 'unanchored' or 'anchored' searches.
#
# This test highlights why. See, we moved "skip over empty matches that split
# a codepoint" down into the core regex engine search APIs. But the way it's
# implemented assumes the search is unanchored. But today, whether it's
# anchored or not depends on the regex engine config *and also* the 'Input'
# config (e.g., if a specific pattern is selected). Which just makes every
# complicated. Instead, we should just have a 'input.get_anchored()' option.
#
# Fixing this for the PikeVM and the backtracker should be pretty easy, since
# it's pretty much already coded as-if 'anchored' was an 'Input' option.
#
# Fixing the non-one-pass DFAs is a little trickier, since we'll need to
# add another explicit anchored starting state for all patterns. This is
# pretty annoying, and I'm also curious how much this might increase automaton
# size... We could make this configurable for the DFAs (with both anchored and
# unanchored enabled by default)... And then panic if an anchored search is
# requested when the DFA doesn't have an anchored starting state?
#
# Hmm, in experiments, it doesn't seem to make the DFA that much bigger. Oh...
# For \w{10} it doubles the size... Sigh. Yup, needs to be configurable. Arrg.
# [[tests]]
# name = "anchored-iter-empty-utf8"
# regex = ''
# input = 'a☃z'
# matches = [[0, 0], [1, 1]]
# unescape = false
# utf8 = true
# anchored = true
